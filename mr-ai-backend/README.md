# ü§ñ MR-AI Backend

A **self-hosted backend** for automated Merge Request (MR) reviews using local/custom AI models.
Works with **GitHub**, **GitLab**, and other Git providers over **SSH**.
Default models: embeddings ‚Äî `dengcao/Qwen3-Embedding-0.6B:Q8_0`, generation ‚Äî `qwen3:32b` (you can change them in settings).

---

## üß≠ Table of Contents

* [Capabilities](#-capabilities)
* [Architecture & Directories](#-architecture--directories)
* [Requirements](#-requirements)
* [Quick Start (Docker)](#-quick-start-docker)
* [Local Install (Rust)](#-local-install-rust)
* [Environment Setup (.env)](#-environment-setup-env)
* [SSH Access to Git](#-ssh-access-to-git)
* [Step-by-Step Workflow](#-step-by-step-workflow)
* [API (cURL Examples)](#-api-curl-examples)
* [AST/Graph Generation](#-astgraph-generation)
* [Practices & Recommendations](#-practices--recommendations)
* [.gitignore](#-gitignore)
* [Switch / Validate Models](#-switch--validate-models)
* [Qdrant GPU Images](#-qdrant-gpu-images)
* [Contributing & License](#-contributing--license)

---

## ‚ú® Capabilities

* üîç Clones code over SSH and prepares a RAG context
* üå≥ Builds syntax trees and code graphs (Tree-sitter)
* üß† Indexes code into a vector DB (Qdrant)
* üí¨ Answers code questions (LLM via Ollama)
* üîó Supports GitHub/GitLab and others via SSH

---

## üóÇÔ∏è Architecture & Directories

```bash
‚îú‚îÄ‚îÄ api/                 # HTTP API server
‚îú‚îÄ‚îÄ services/            # Services & utilities
‚îú‚îÄ‚îÄ contextor/           # Answer orchestration: query RAG ‚Üí LLM response
‚îú‚îÄ‚îÄ code_data/           # Project data: clones, artifacts, indexes
‚îú‚îÄ‚îÄ codegraph-prep/      # Build syntax trees and code graph (primary module)
‚îú‚îÄ‚îÄ graph-prepare/       # Historical module; use codegraph-prep instead
‚îú‚îÄ‚îÄ vector-lib/          # Vector data helpers
‚îú‚îÄ‚îÄ rag-store/           # Convert code graph into vector DB format
‚îú‚îÄ‚îÄ ssh_keys/            # SSH keys for repo access
‚îú‚îÄ‚îÄ .env                 # Project environment variables
‚îú‚îÄ‚îÄ docker-compose.yml   # Ollama + Qdrant services
‚îú‚îÄ‚îÄ bootstrap_ollama.sh  # Helper to spin up dependencies via docker-compose
```

> ‚ÑπÔ∏è **Inconsistencies fixed:** unified ports/URLs, single graph module (`codegraph-prep`), consistent env names.

---

## üß© Requirements

* üê≥ Docker / Docker Compose ‚Äî easiest way to start
* ü¶Ä Rust (stable) ‚Äî if running the API without Docker
* üì¶ \~8‚Äì30 GB free disk space (models + indexes)
* üîê SSH access to your Git repositories

---

## üöÄ Quick Start (Docker)

1. **Create and adjust `.env`** (see template below).
2. **Start dependencies** (Ollama + Qdrant):

   ```bash
   chmod +x ./bootstrap_ollama.sh
   ./bootstrap_ollama.sh
   # custom names/files:
   ./bootstrap_ollama.sh -f docker-compose.yml -n ollama
   ```
3. **Check Qdrant:**

   * UI/HTTP: [http://localhost:6333](http://localhost:6333)
   * Health check:

     ```bash
     curl -s http://localhost:6333/readyz
     ```
4. **Run the API (if not containerized):**

   ```bash
   cargo run --release
   ```

---

## üõ† Local Install (Rust)

1. Install Rust and system deps (cmake, build tools, etc.).
2. Configure `.env`.
3. Run:

   ```bash
   cargo run --release
   ```

---

## ‚öôÔ∏è Environment Setup (.env)

```env
############################
# üîπ General
############################
PROJECT_NAME=project_x
API_ADDRESS=0.0.0.0:3000

############################
# üîπ Ollama / LLM
############################
# Default Ollama port: 11434
OLLAMA_HOST=http://localhost
OLLAMA_PORT=11434
OLLAMA_URL=${OLLAMA_HOST}:${OLLAMA_PORT}
OLLAMA_MODEL=qwen3:32b

############################
# üîπ Embeddings
############################
EMBEDDING_MODEL=dengcao/Qwen3-Embedding-0.6B:Q8_0
EMBEDDING_DIM=1024            # Verify this matches the model (see below)
EMBEDDING_CONCURRENCY=4

############################
# üîπ Qdrant (Vector DB)
############################
QDRANT_HTTP_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_URL=http://localhost:${QDRANT_HTTP_PORT}
QDRANT_COLLECTION=mr_ai_code
QDRANT_DISTANCE=Cosine
QDRANT_BATCH_SIZE=256

############################
# üîπ Chunking
############################
CHUNK_MAX_CHARS=4000
CHUNK_MIN_CHARS=16

############################
# üîπ Graph Export
############################
GRAPH_EXPORT_DIR_NAME=graphs_data
GRAPH_EXCLUDE_GENERATED=true
GRAPH_GENERATED_GLOBS=**/*.g.dart,**/*.freezed.dart

############################
# üîπ Debug
############################
# RUST_BACKTRACE=1
# AST_TARGET_SUFFIX=packages/home_feature/lib/src/presentation/ui/base_home_page.dart
```

> üí° You can run **multiple projects** by changing `PROJECT_NAME`; each gets its own directory under `code_data/`.

---

## üîê SSH Access to Git

### 1) Generate a key

```bash
ssh-keygen -t ed25519 -C "bot@mr-ai.com" -f ./ssh_keys/bot_key
```

Creates:

* private: `ssh_keys/bot_key`
* public:  `ssh_keys/bot_key.pub`

> ‚ö†Ô∏è Never commit private keys.

### 2) Add the public key to your provider

* **GitHub:** Settings ‚Üí *SSH and GPG Keys* ‚Üí *New SSH Key*
* **GitLab:** User Settings ‚Üí *SSH Keys*
  Paste the contents of `ssh_keys/bot_key.pub`.

### 3) Accept host fingerprints (for `libgit2`)

```bash
ssh-keyscan gitlab.com >> ~/.ssh/known_hosts
# add others as needed (github.com, bitbucket.org, etc.)
```

---

## üß™ Step-by-Step Workflow

1. **Start dependencies** (Ollama + Qdrant) ‚Üí `./bootstrap_ollama.sh`
2. **Run the API** ‚Üí `cargo run --release`
3. **Attach repository** ‚Üí `POST /upload_project_data` with SSH URL(s)
4. **Learn code** ‚Üí `POST /learn_code`
5. **Prepare code graph** ‚Üí `POST /prepare_graph`
6. **Initialize Qdrant** ‚Üí `POST /prepare_qdrant`
7. **Ask questions about the code** ‚Üí `POST /ask_question`

---

## üõ∞Ô∏è API (cURL Examples)

> Base URL comes from `API_ADDRESS` (default `0.0.0.0:3000`).

**Ask a question about the code**

```bash
curl --location 'http://0.0.0.0:3000/ask_question' \
--header 'Content-Type: application/json' \
--data '{
  "question": "How can I replace the icon in the navigation bar for the Games section in AppHomePage?"
}'
```

**Attach repository(ies)**

```bash
curl --location 'http://0.0.0.0:3000/upload_project_data' \
--header 'Content-Type: application/json' \
--data-raw '{
  "urls": ["git@gitlab.com:kulllgar/testprojectmain.git"]
}'
```

**Learn code**

```bash
curl --location 'http://0.0.0.0:3000/learn_code'
```

**Prepare graph**

```bash
curl --location 'http://0.0.0.0:3000/prepare_graph'
```

**Initialize Qdrant**

```bash
curl --location 'http://0.0.0.0:3000/prepare_qdrant'
```

---

## üå≥ AST/Graph Generation

Uses [Tree-sitter](https://tree-sitter.github.io/tree-sitter) to parse code and build the graph.

**Supported languages:**

* ‚úÖ Dart (ready)
* üöß Rust, Python, JavaScript, TypeScript (in progress)

**Artifacts location:**

```
code_data/<PROJECT_NAME>/graphs_data/<timestamp>/
```

Contents:

* `graph.graphml` ‚Äî open in [Gephi](https://gephi.org/)
* `ast_nodes.jsonl`, `graph_nodes.jsonl`, `graph_edges.jsonl`
* `summary.json` ‚Äî metadata

### Dart AST Debugging

**Env vars**

* `PROJECT_NAME` ‚Äî required; code root is `code_data/{PROJECT_NAME}`
* `AST_TARGET_SUFFIX` ‚Äî path suffix to the Dart file, e.g.
  `lib/features/splash/presentation/state/splash_state.dart`

**Run**

```bash
PROJECT_NAME=project_x \
AST_TARGET_SUFFIX=lib/features/splash/presentation/state/splash_state.dart \
cargo run --bin dart-ast-dump
```

---

## ‚úÖ Practices & Recommendations

* üîí **Secrets:** keep keys in `ssh_keys/`; **never commit** private ones.
* üßπ **Clean diffs:** ignore artifact folders (`code_data/`, `ssh_keys/`).
* üìè **Chunking:** tune `CHUNK_MAX_CHARS` / `CHUNK_MIN_CHARS` per language/size.
* üß™ **Embedding size:** ensure `EMBEDDING_DIM` matches the embedding model (see below).
* üß© **Module duplication:** prefer `codegraph-prep` (over `graph-prepare`).

---

## üìù .gitignore

```gitignore
# Project data & artifacts
code_data/*
!code_data/.gitkeep

# SSH keys
ssh_keys/*
!ssh_keys/.gitkeep

# Local env & build
.env
target/
```

---

## üîÑ Switch / Validate Models

**Install or switch models in Ollama:**

```bash
docker exec -it ollama ollama pull dengcao/Qwen3-Embedding-0.6B:Q8_0
docker exec -it ollama ollama pull qwen3:32b
```

**Validate embedding dimensionality (`EMBEDDING_DIM`):**

```bash
curl --location 'http://localhost:11434/api/embed' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "dengcao/Qwen3-Embedding-0.6B:Q8_0",
    "input": "hello"
  }'
# response contains "embedding": [...] ‚Äî check the vector length
```

---

## ‚ö° Qdrant GPU Images

Available images:

* **NVIDIA** ‚Äî `qdrant/qdrant:gpu-nvidia-latest`
* **AMD ROCm** ‚Äî `qdrant/qdrant:gpu-amd-latest`

> See Qdrant docs for full GPU configuration details.

---

## ü§ù Contributing & License

PRs welcome: new language support, performance improvements, bug fixes.
Open an issue/PR describing your changes.

**License:** FSL-1.1.

---
